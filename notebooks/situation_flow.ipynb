{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e47404",
   "metadata": {},
   "source": [
    "# Situation Flow Notebook (WIP)\n",
    "\n",
    "Standalone notebook to manage situations using the same data submodules (`data/`, `situations/`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60abd96a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "- Ensure submodules are pulled: `!git submodule update --init --recursive`\n",
    "- Install deps: `pip install ipywidgets openai`\n",
    "- The notebook reads/writes the existing `data/gloss/{lang}/*.json` files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32f9212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except Exception as exc:  # noqa: BLE001\n",
    "    raise RuntimeError(\"Install the openai package: pip install openai\") from exc\n",
    "\n",
    "client = OpenAI()  # expects OPENAI_API_KEY in env\n",
    "\n",
    "# Adjust if you move the notebook; assumes /notebooks relative to repo root.\n",
    "repo_root = Path.cwd().resolve().parent\n",
    "DATA_ROOT = repo_root / \"data\"\n",
    "if not DATA_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Expected data directory at {DATA_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c0b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Gloss model ---\n",
    "\n",
    "def normalize_language_code(code: str | None) -> str:\n",
    "    return (code or \"\").strip().lower()\n",
    "\n",
    "\n",
    "def derive_slug(text: str) -> str:\n",
    "    text = (text or \"\").strip().lower()\n",
    "    text = re.sub(r\"[^a-z0-9]+\", \"-\", text)\n",
    "    text = re.sub(r\"-+\", \"-\", text).strip(\"-\")\n",
    "    return text\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Gloss:\n",
    "    content: str\n",
    "    language: str = \"und\"\n",
    "    transcriptions: dict[str, str] = field(default_factory=dict)\n",
    "    logs: dict[str, str] = field(default_factory=dict)\n",
    "    morphologically_related: list[str] = field(default_factory=list)\n",
    "    parts: list[str] = field(default_factory=list)\n",
    "    has_similar_meaning: list[str] = field(default_factory=list)\n",
    "    sounds_similar: list[str] = field(default_factory=list)\n",
    "    usage_examples: list[str] = field(default_factory=list)\n",
    "    to_be_differentiated_from: list[str] = field(default_factory=list)\n",
    "    collocations: list[str] = field(default_factory=list)\n",
    "    typical_follow_up: list[str] = field(default_factory=list)\n",
    "    children: list[str] = field(default_factory=list)\n",
    "    translations: list[str] = field(default_factory=list)\n",
    "    notes: list[str] = field(default_factory=list)\n",
    "    tags: list[str] = field(default_factory=list)\n",
    "    slug: str | None = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: dict[str, Any], slug: str | None = None, language: str | None = None) -> \"Gloss\":\n",
    "        return cls(\n",
    "            content=data.get(\"content\", \"\"),\n",
    "            language=normalize_language_code(language or data.get(\"language\", \"und\")),\n",
    "            transcriptions=dict(data.get(\"transcriptions\", {}) or {}),\n",
    "            logs=dict(data.get(\"logs\", {}) or {}),\n",
    "            morphologically_related=list(data.get(\"morphologically_related\", []) or []),\n",
    "            parts=list(data.get(\"parts\", []) or []),\n",
    "            has_similar_meaning=list(data.get(\"has_similar_meaning\", []) or []),\n",
    "            sounds_similar=list(data.get(\"sounds_similar\", []) or []),\n",
    "            usage_examples=list(data.get(\"usage_examples\", []) or []),\n",
    "            to_be_differentiated_from=list(data.get(\"to_be_differentiated_from\", []) or []),\n",
    "            collocations=list(data.get(\"collocations\", []) or []),\n",
    "            typical_follow_up=list(data.get(\"typical_follow_up\", []) or []),\n",
    "            children=list(data.get(\"children\", []) or []),\n",
    "            translations=list(data.get(\"translations\", []) or []),\n",
    "            notes=list(data.get(\"notes\", []) or []),\n",
    "            tags=list(data.get(\"tags\", []) or []),\n",
    "            slug=slug,\n",
    "        )\n",
    "\n",
    "    def to_dict(self) -> dict[str, Any]:\n",
    "        return {\n",
    "            \"content\": self.content,\n",
    "            \"language\": normalize_language_code(self.language),\n",
    "            \"transcriptions\": self.transcriptions,\n",
    "            \"logs\": self.logs,\n",
    "            \"morphologically_related\": self.morphologically_related,\n",
    "            \"parts\": self.parts,\n",
    "            \"has_similar_meaning\": self.has_similar_meaning,\n",
    "            \"sounds_similar\": self.sounds_similar,\n",
    "            \"usage_examples\": self.usage_examples,\n",
    "            \"to_be_differentiated_from\": self.to_be_differentiated_from,\n",
    "            \"collocations\": self.collocations,\n",
    "            \"typical_follow_up\": self.typical_follow_up,\n",
    "            \"children\": self.children,\n",
    "            \"translations\": self.translations,\n",
    "            \"notes\": self.notes,\n",
    "            \"tags\": self.tags,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74abb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Storage helpers (filesystem-backed, same layout as the app) ---\n",
    "\n",
    "RELATIONSHIP_FIELDS = [\n",
    "    \"morphologically_related\",\n",
    "    \"parts\",\n",
    "    \"has_similar_meaning\",\n",
    "    \"sounds_similar\",\n",
    "    \"usage_examples\",\n",
    "    \"to_be_differentiated_from\",\n",
    "    \"collocations\",\n",
    "    \"typical_follow_up\",\n",
    "    \"children\",\n",
    "    \"translations\",\n",
    "    \"notes\",\n",
    "    \"tags\",\n",
    "]\n",
    "\n",
    "\n",
    "class GlossStorage:\n",
    "    def __init__(self, data_root: Path):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.gloss_root = self.data_root / \"gloss\"\n",
    "        if not self.gloss_root.exists():\n",
    "            raise FileNotFoundError(f\"Gloss directory not found: {self.gloss_root}\")\n",
    "\n",
    "    def _language_dir(self, language: str) -> Path:\n",
    "        lang = normalize_language_code(language)\n",
    "        target = self.gloss_root / lang\n",
    "        target.mkdir(parents=True, exist_ok=True)\n",
    "        return target\n",
    "\n",
    "    def _path_for(self, language: str, slug: str) -> Path:\n",
    "        return self._language_dir(language) / f\"{slug}.json\"\n",
    "\n",
    "    def list_glosses(self) -> list[Gloss]:\n",
    "        glosses: list[Gloss] = []\n",
    "        if not self.gloss_root.exists():\n",
    "            return glosses\n",
    "        for language_dir in sorted(self.gloss_root.iterdir()):\n",
    "            if not language_dir.is_dir():\n",
    "                continue\n",
    "            for gloss_file in sorted(language_dir.glob(\"*.json\")):\n",
    "                with gloss_file.open(\"r\", encoding=\"utf-8\") as handle:\n",
    "                    data = json.load(handle)\n",
    "                gloss = Gloss.from_dict(data, slug=gloss_file.stem, language=language_dir.name)\n",
    "                glosses.append(gloss)\n",
    "        return glosses\n",
    "\n",
    "    def load_gloss(self, language: str, slug: str) -> Gloss | None:\n",
    "        path = self._path_for(language, slug)\n",
    "        if not path.exists():\n",
    "            return None\n",
    "        with path.open(\"r\", encoding=\"utf-8\") as handle:\n",
    "            data = json.load(handle)\n",
    "        return Gloss.from_dict(data, slug=slug, language=language)\n",
    "\n",
    "    def find_gloss_by_slug(self, language: str, slug: str) -> Gloss | None:\n",
    "        return self.load_gloss(normalize_language_code(language), slug)\n",
    "\n",
    "    def create_gloss(self, gloss: Gloss) -> Gloss:\n",
    "        slug = derive_slug(gloss.content)\n",
    "        if not slug:\n",
    "            raise ValueError(\"Content must produce a valid slug.\")\n",
    "        language = normalize_language_code(gloss.language)\n",
    "        target = self._path_for(language, slug)\n",
    "        if target.exists():\n",
    "            raise FileExistsError(f\"Gloss already exists: {language}:{slug}\")\n",
    "        self._write_gloss(target, gloss)\n",
    "        gloss.slug = slug\n",
    "        gloss.language = language\n",
    "        return gloss\n",
    "\n",
    "    def save_gloss(self, gloss: Gloss) -> Gloss:\n",
    "        if not gloss.slug or not gloss.language:\n",
    "            raise ValueError(\"Gloss must have language and slug before saving.\")\n",
    "        target = self._path_for(gloss.language, gloss.slug)\n",
    "        self._write_gloss(target, gloss)\n",
    "        return gloss\n",
    "\n",
    "    def ensure_gloss(self, language: str, content: str) -> Gloss:\n",
    "        language = normalize_language_code(language)\n",
    "        existing = self.find_gloss_by_content(language, content)\n",
    "        if existing:\n",
    "            return existing\n",
    "        new_gloss = Gloss(content=content, language=language)\n",
    "        return self.create_gloss(new_gloss)\n",
    "\n",
    "    def find_gloss_by_content(self, language: str, content: str) -> Gloss | None:\n",
    "        language = normalize_language_code(language)\n",
    "        slug = derive_slug(content)\n",
    "        if not slug:\n",
    "            return None\n",
    "        return self.load_gloss(language, slug)\n",
    "\n",
    "    def resolve_reference(self, ref: str) -> Gloss | None:\n",
    "        if \":\" not in ref:\n",
    "            return None\n",
    "        language, slug = ref.split(\":\", 1)\n",
    "        language = normalize_language_code(language)\n",
    "        slug = slug.strip()\n",
    "        if not slug:\n",
    "            return None\n",
    "        return self.load_gloss(language, slug)\n",
    "\n",
    "    def _write_gloss(self, path: Path, gloss: Gloss) -> None:\n",
    "        payload = gloss.to_dict()\n",
    "        with path.open(\"w\", encoding=\"utf-8\") as handle:\n",
    "            json.dump(payload, handle, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def attach_relation(storage: GlossStorage, source: Gloss, field: str, target: Gloss) -> None:\n",
    "    if field not in RELATIONSHIP_FIELDS:\n",
    "        raise ValueError(f\"Unknown relationship field: {field}\")\n",
    "    refs = getattr(source, field, []) or []\n",
    "    ref = f\"{target.language}:{target.slug or derive_slug(target.content)}\"\n",
    "    if ref not in refs:\n",
    "        refs = list(refs) + [ref]\n",
    "        setattr(source, field, refs)\n",
    "        storage.save_gloss(source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37670102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Situation logic (adapted from sbll_cms/situations_logic.py) ---\n",
    "\n",
    "SPLIT_LOG_MARKER = \"SPLIT_CONSIDERED_UNNECESSARY\"\n",
    "TRANSLATION_IMPOSSIBLE_MARKER = \"TRANSLATION_CONSIDERED_IMPOSSIBLE\"\n",
    "USAGE_IMPOSSIBLE_MARKER = \"USAGE_EXAMPLE_CONSIDERED_IMPOSSIBLE\"\n",
    "\n",
    "\n",
    "def paraphrase_display(gloss: Gloss) -> str:\n",
    "    text = gloss.content or gloss.slug or \"\"\n",
    "    if gloss.slug and gloss.slug not in text:\n",
    "        text = f\"{text} ({gloss.slug})\"\n",
    "    return text\n",
    "\n",
    "\n",
    "def build_goal_nodes(situation: Gloss, storage: GlossStorage, native_language: str, target_language: str):\n",
    "    stats = {\n",
    "        \"situation_glosses\": set(),\n",
    "        \"glosses_to_learn\": set(),\n",
    "        \"native_missing\": set(),\n",
    "        \"target_missing\": set(),\n",
    "        \"parts_missing\": set(),\n",
    "        \"usage_missing\": set(),\n",
    "        \"gloss_map\": {},\n",
    "    }\n",
    "    seen_keys: set[str] = set()\n",
    "    nodes = []\n",
    "\n",
    "    def gloss_key(gl):\n",
    "        return f\"{gl.language}:{gl.slug or gl.content}\"\n",
    "\n",
    "    def has_log(gl, marker: str) -> bool:\n",
    "        logs = getattr(gl, \"logs\", {}) or {}\n",
    "        if not isinstance(logs, dict):\n",
    "            return False\n",
    "        return any(marker in str(val) for val in logs.values())\n",
    "\n",
    "    def has_translation(gl, lang: str) -> bool:\n",
    "        return any(ref.startswith(f\"{lang}:\") for ref in (gl.translations or []))\n",
    "\n",
    "    def mark_stats(gl, usage_lineage: bool, parts_line: bool, learn_lang: str):\n",
    "        key = gloss_key(gl)\n",
    "        stats[\"gloss_map\"][key] = gl\n",
    "        stats[\"situation_glosses\"].add(key)\n",
    "\n",
    "        if not (getattr(gl, \"parts\", None) or []) and not has_log(gl, SPLIT_LOG_MARKER):\n",
    "            stats[\"parts_missing\"].add(key)\n",
    "\n",
    "        if gl.language == target_language:\n",
    "            if not has_translation(gl, native_language) and not has_log(gl, f\"{TRANSLATION_IMPOSSIBLE_MARKER}:{native_language}\"):\n",
    "                stats[\"native_missing\"].add(key)\n",
    "            if not usage_lineage and not has_log(gl, f\"{USAGE_IMPOSSIBLE_MARKER}:{target_language}\") and not (gl.usage_examples or []):\n",
    "                stats[\"usage_missing\"].add(key)\n",
    "        elif gl.language == native_language:\n",
    "            if not has_translation(gl, target_language) and not has_log(gl, f\"{TRANSLATION_IMPOSSIBLE_MARKER}:{target_language}\"):\n",
    "                stats[\"target_missing\"].add(key)\n",
    "\n",
    "        if parts_line and gl.language == learn_lang:\n",
    "            stats[\"glosses_to_learn\"].add(key)\n",
    "\n",
    "        return {\n",
    "            \"warn_native_missing\": key in stats[\"native_missing\"],\n",
    "            \"warn_target_missing\": key in stats[\"target_missing\"],\n",
    "            \"warn_usage_missing\": key in stats[\"usage_missing\"],\n",
    "        }\n",
    "\n",
    "    def build_node(gloss, role=\"root\", marker=\"\", usage_lineage=False, allow_translations=True, path=None, parts_line=False, learn_lang=\"\"):\n",
    "        tags = gloss.tags or []\n",
    "        if gloss.language == target_language and \"eng:paraphrase\" in tags:\n",
    "            return None\n",
    "\n",
    "        path = set(path or [])\n",
    "        key = gloss_key(gloss)\n",
    "        seen_keys.add(key)\n",
    "\n",
    "        flags = mark_stats(gloss, usage_lineage, parts_line, learn_lang)\n",
    "\n",
    "        node = {\n",
    "            \"gloss\": gloss,\n",
    "            \"children\": [],\n",
    "            \"marker\": marker,\n",
    "            \"bold\": parts_line and gloss.language == learn_lang,\n",
    "            \"role\": role,\n",
    "            \"warn_native_missing\": flags[\"warn_native_missing\"],\n",
    "            \"warn_target_missing\": flags[\"warn_target_missing\"],\n",
    "            \"warn_usage_missing\": flags[\"warn_usage_missing\"],\n",
    "            \"warn_parts_missing\": key in stats[\"parts_missing\"],\n",
    "        }\n",
    "\n",
    "        if key in path:\n",
    "            return node\n",
    "        next_path = set(path or [])\n",
    "        next_path.add(key)\n",
    "\n",
    "        if role in (\"root\", \"part\", \"usage_part\"):\n",
    "            stats[\"glosses_to_learn\"].add(key)\n",
    "\n",
    "        for part_ref in getattr(gloss, \"parts\", []):\n",
    "            part_gloss = storage.resolve_reference(part_ref)\n",
    "            if not part_gloss:\n",
    "                continue\n",
    "            child_parts_line = parts_line if role == \"root\" else False\n",
    "            part_node = build_node(\n",
    "                part_gloss,\n",
    "                role=\"usage_part\" if role in (\"usage\", \"usage_part\") else \"part\",\n",
    "                usage_lineage=usage_lineage,\n",
    "                allow_translations=True,\n",
    "                path=next_path,\n",
    "                parts_line=child_parts_line,\n",
    "                learn_lang=learn_lang,\n",
    "            )\n",
    "            if part_node:\n",
    "                node[\"children\"].append(part_node)\n",
    "\n",
    "        if allow_translations:\n",
    "            other_lang = None\n",
    "            if gloss.language == native_language and target_language:\n",
    "                other_lang = target_language\n",
    "            elif gloss.language == target_language and native_language:\n",
    "                other_lang = native_language\n",
    "            if other_lang:\n",
    "                for ref in gloss.translations or []:\n",
    "                    ref_lang = ref.split(\":\", 1)[0].strip().lower()\n",
    "                    if ref_lang != other_lang.lower():\n",
    "                        continue\n",
    "                    t_gloss = storage.resolve_reference(ref)\n",
    "                    if not t_gloss:\n",
    "                        continue\n",
    "                    child_key = gloss_key(t_gloss)\n",
    "                    t_node = build_node(\n",
    "                        t_gloss,\n",
    "                        role=\"translation\",\n",
    "                        marker=\"\",\n",
    "                        usage_lineage=usage_lineage,\n",
    "                        allow_translations=child_key not in next_path,\n",
    "                        path=next_path,\n",
    "                        parts_line=False,\n",
    "                        learn_lang=learn_lang,\n",
    "                    )\n",
    "                    if t_node:\n",
    "                        node[\"children\"].append(t_node)\n",
    "\n",
    "        if gloss.language == target_language and not usage_lineage:\n",
    "            if gloss.usage_examples:\n",
    "                for u_ref in getattr(gloss, \"usage_examples\", []):\n",
    "                    u_gloss = storage.resolve_reference(u_ref)\n",
    "                    if not u_gloss:\n",
    "                        continue\n",
    "                    usage_node = build_node(\n",
    "                        u_gloss,\n",
    "                        role=\"usage\",\n",
    "                        marker=\"USG \",\n",
    "                        usage_lineage=True,\n",
    "                        allow_translations=True,\n",
    "                        path=next_path,\n",
    "                        parts_line=False,\n",
    "                        learn_lang=learn_lang,\n",
    "                    )\n",
    "                    if usage_node:\n",
    "                        node[\"children\"].append(usage_node)\n",
    "\n",
    "        return node\n",
    "\n",
    "    for ref in situation.children:\n",
    "        gloss = storage.resolve_reference(ref)\n",
    "        if not gloss:\n",
    "            continue\n",
    "        tags = gloss.tags or []\n",
    "        marker = \"\"\n",
    "        if gloss.language == native_language and \"eng:procedural-paraphrase-expression-goal\" in tags:\n",
    "            marker = \"PROC \"\n",
    "            learn_lang = native_language\n",
    "            goal_type = \"procedural\"\n",
    "        elif gloss.language == target_language and \"eng:understand-expression-goal\" in tags:\n",
    "            marker = \"UNDR \"\n",
    "            learn_lang = target_language\n",
    "            goal_type = \"understand\"\n",
    "        else:\n",
    "            continue\n",
    "        node = build_node(\n",
    "            gloss,\n",
    "            role=\"root\",\n",
    "            marker=marker,\n",
    "            usage_lineage=False,\n",
    "            allow_translations=True,\n",
    "            parts_line=True,\n",
    "            learn_lang=learn_lang,\n",
    "        )\n",
    "        if node:\n",
    "            node[\"goal_type\"] = goal_type\n",
    "            nodes.append(node)\n",
    "    return nodes, stats\n",
    "\n",
    "\n",
    "def render_tree(nodes: list[dict[str, Any]]):\n",
    "    lines: list[str] = []\n",
    "\n",
    "    def label_for(node):\n",
    "        gloss = node[\"gloss\"]\n",
    "        text = paraphrase_display(gloss)\n",
    "        markers_after = \"\"\n",
    "        if node.get(\"warn_native_missing\") or node.get(\"warn_target_missing\"):\n",
    "            markers_after += \" [WARN-TRANSLATION]\"\n",
    "        if node.get(\"warn_usage_missing\"):\n",
    "            markers_after += \" [WARN-USAGE]\"\n",
    "        if node.get(\"warn_parts_missing\"):\n",
    "            markers_after += \" [WARN-PARTS]\"\n",
    "        content = f\"{text}{markers_after}\"\n",
    "        if node.get(\"bold\"):\n",
    "            content = f\"**{content}**\"\n",
    "        return content\n",
    "\n",
    "    def walk(node_list, prefix=\"\"):\n",
    "        total = len(node_list)\n",
    "        for idx, node in enumerate(node_list):\n",
    "            is_last = idx == total - 1\n",
    "            connector = \"`-- \" if is_last else \"|-- \"\n",
    "            lines.append(f\"{prefix}{connector}{node.get('marker', '')}{label_for(node)}\")\n",
    "            if node.get(\"children\"):\n",
    "                walk(node[\"children\"], f\"{prefix}{'    ' if is_last else '|   '}\")\n",
    "\n",
    "    walk(nodes)\n",
    "    return lines\n",
    "\n",
    "\n",
    "def collect_situation_stats(storage: GlossStorage, situation: Gloss, native_language: str, target_language: str):\n",
    "    _nodes, stats = build_goal_nodes(\n",
    "        situation,\n",
    "        storage=storage,\n",
    "        native_language=native_language,\n",
    "        target_language=target_language,\n",
    "    )\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d440542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 492 glosses from /home/brokkoli/GITHUB/glosses4learning-cms/data\n"
     ]
    }
   ],
   "source": [
    "# --- Load glosses and derive situation list ---\n",
    "\n",
    "storage = GlossStorage(DATA_ROOT)\n",
    "all_glosses = storage.list_glosses()\n",
    "print(f\"Loaded {len(all_glosses)} glosses from {DATA_ROOT}\")\n",
    "\n",
    "situations = [g for g in all_glosses if \"eng:situation\" in (g.tags or [])]\n",
    "lang_codes = sorted({g.language for g in all_glosses})\n",
    "if not situations:\n",
    "    print(\"No situations found. Check that data submodule is present.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48a0a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a139f1c513f34f4a8e6c342ca4df4c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Situation manager</h3>'), Dropdown(description='Situation', options=(('at the aâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86b0f3f40e24a5da0c9cd21e84d0843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<em>No situation selected.</em>'),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Manager view: pick situation + languages, then open flow ---\n",
    "\n",
    "selection = {\"situation_ref\": None, \"native_language\": None, \"target_language\": None}\n",
    "\n",
    "situation_options = [\n",
    "    (f\"{g.content} [{g.language}:{g.slug}]\", f\"{g.language}:{g.slug}\") for g in situations\n",
    "]\n",
    "\n",
    "situation_dd = widgets.Dropdown(options=situation_options, description=\"Situation\")\n",
    "native_dd = widgets.Dropdown(options=lang_codes, description=\"Native\")\n",
    "target_dd = widgets.Dropdown(options=lang_codes, description=\"Target\")\n",
    "open_btn = widgets.Button(description=\"Open detailed flow\", button_style=\"primary\")\n",
    "status_out = widgets.Output()\n",
    "stats_out = widgets.Output()\n",
    "tree_out = widgets.Output()\n",
    "flow_box = widgets.VBox([widgets.HTML(\"<em>No situation selected.</em>\")])\n",
    "\n",
    "\n",
    "def refresh_view():\n",
    "    tree_out.clear_output()\n",
    "    stats_out.clear_output()\n",
    "    if not selection[\"situation_ref\"] or not selection[\"native_language\"] or not selection[\"target_language\"]:\n",
    "        flow_box.children = [widgets.HTML(\"<em>Select a situation and languages.</em>\")]\n",
    "        return\n",
    "    situation = storage.resolve_reference(selection[\"situation_ref\"])\n",
    "    if not situation:\n",
    "        flow_box.children = [widgets.HTML(f\"<b>Missing situation</b>: {selection['situation_ref']}\")]\n",
    "        return\n",
    "    nodes, stats = build_goal_nodes(\n",
    "        situation,\n",
    "        storage=storage,\n",
    "        native_language=selection[\"native_language\"],\n",
    "        target_language=selection[\"target_language\"],\n",
    "    )\n",
    "    lines = render_tree(nodes)\n",
    "    with tree_out:\n",
    "        display(widgets.HTML(f\"<pre>{'\\\\n'.join(lines) or '(no tree)'}</pre>\"))\n",
    "    with stats_out:\n",
    "        summary = {\n",
    "            \"parts_missing\": len(stats.get(\"parts_missing\", [])),\n",
    "            \"native_missing\": len(stats.get(\"native_missing\", [])),\n",
    "            \"target_missing\": len(stats.get(\"target_missing\", [])),\n",
    "            \"usage_missing\": len(stats.get(\"usage_missing\", [])),\n",
    "            \"glosses_to_learn\": len(stats.get(\"glosses_to_learn\", [])),\n",
    "        }\n",
    "        print(\"Stats:\", summary)\n",
    "    header = widgets.HTML(\n",
    "        f\"<b>Flow for</b> {situation.content} &nbsp;|&nbsp; Native: {selection['native_language']} &nbsp; Target: {selection['target_language']}\"\n",
    "    )\n",
    "    todo = widgets.HTML(\"<em>Tool panels go here (generate/accept goals, translations, splits, examples).</em>\")\n",
    "    flow_box.children = [header, stats_out, tree_out, todo]\n",
    "\n",
    "\n",
    "def on_open_clicked(_):\n",
    "    selection[\"situation_ref\"] = situation_dd.value\n",
    "    selection[\"native_language\"] = native_dd.value\n",
    "    selection[\"target_language\"] = target_dd.value\n",
    "    with status_out:\n",
    "        status_out.clear_output()\n",
    "        print(\n",
    "            f\"Selected {selection['situation_ref']} | native={selection['native_language']} | target={selection['target_language']}\"\n",
    "        )\n",
    "    refresh_view()\n",
    "\n",
    "\n",
    "open_btn.on_click(on_open_clicked)\n",
    "\n",
    "manager_box = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Situation manager</h3>\"),\n",
    "    situation_dd,\n",
    "    widgets.HBox([native_dd, target_dd]),\n",
    "    open_btn,\n",
    "    status_out,\n",
    "])\n",
    "\n",
    "display(manager_box)\n",
    "display(flow_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239d522-f7da-48a3-9547-580a4937b028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
